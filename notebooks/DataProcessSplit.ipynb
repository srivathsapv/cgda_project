{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srivathsa/miniconda3/envs/superpacs/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: The reduce argument is deprecated and will be removed in a future version. You can specify result_type='reduce' to try to reduce the result to the original dimensions\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_taxa = pd.read_csv('taxa.csv')\n",
    "df_taxa = df_taxa[df_taxa.apply(lambda r: set(list(r['sequence'])) == {'G', 'C', 'A', 'T'}, axis=1, reduce=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_csv(data, labels, fpath_split):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_nos = label_encoder.fit_transform(labels)\n",
    "    data_rows = []\n",
    "    for i, (row_id, sequence) in enumerate(data):\n",
    "        data_dict = {}\n",
    "        data_dict['id'] = row_id\n",
    "        data_dict['sequence'] = sequence\n",
    "        data_dict['class_name'] = labels[i]\n",
    "        data_dict['label'] = label_nos[i]\n",
    "        data_rows.append(data_dict)\n",
    "    \n",
    "    df_split = pd.DataFrame(data_rows)\n",
    "    df_split.to_csv(fpath_split, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_from_df(df_taxa, level):\n",
    "    ids = df_taxa['id'].values\n",
    "    seqs = df_taxa['sequence'].values\n",
    "\n",
    "    X = np.vstack([ids, seqs]).T\n",
    "    y = df_taxa[level].values\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def split_phylum_data(df_taxa, split_ratio=0.33):\n",
    "    level = 'phylum'\n",
    "    X, y = get_xy_from_df(df_taxa, level)\n",
    "    \n",
    "    _, data, _, labels = train_test_split(X, y, test_size=split_ratio, stratify=y, shuffle=True)\n",
    "\n",
    "    (train_data, testval_data, train_labels, testval_labels) = \\\n",
    "        train_test_split(data, labels, test_size=0.4, stratify=labels, shuffle=True)\n",
    "\n",
    "    (test_data, val_data, test_labels, val_labels) = \\\n",
    "        train_test_split(testval_data, testval_labels, test_size=0.5, stratify=testval_labels, shuffle=True)\n",
    "\n",
    "    create_split_csv(train_data, train_labels, '../data/hierarchy/{}/train.csv'.format(level))\n",
    "    create_split_csv(test_data, test_labels, '../data/hierarchy/{}/test.csv'.format(level))\n",
    "    create_split_csv(val_data, val_labels, '../data/hierarchy/{}/val.csv'.format(level))\n",
    "\n",
    "def split_data(df_taxa, level='class', n_samples_per_class=2e4):\n",
    "    df_group = df_taxa.sample(frac=1).groupby(by=level)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for name, group in df_group:\n",
    "        gX, gy = get_xy_from_df(group, level)\n",
    "        gX = gX[:int(n_samples_per_class)]\n",
    "        gy = gy[:int(n_samples_per_class)]\n",
    "        X.append(gX)\n",
    "        y.append(gy)\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    y = np.concatenate(y)\n",
    "    \n",
    "    print(np.unique(y, return_counts=True))\n",
    "    (train_data, testval_data, train_labels, testval_labels) = \\\n",
    "        train_test_split(X, y, test_size=0.4, stratify=y, shuffle=True)\n",
    "    \n",
    "    (test_data, val_data, test_labels, val_labels) = \\\n",
    "        train_test_split(testval_data, testval_labels, test_size=0.5, stratify=testval_labels, shuffle=True)\n",
    "    \n",
    "    create_split_csv(train_data, train_labels, '../data/hierarchy/{}/train.csv'.format(level))\n",
    "    create_split_csv(test_data, test_labels, '../data/hierarchy/{}/test.csv'.format(level))\n",
    "    create_split_csv(val_data, val_labels, '../data/hierarchy/{}/val.csv'.format(level))\n",
    "\n",
    "def group_labels(df_taxa, label_names):\n",
    "    df_group = df_taxa\n",
    "    grouped_label_name = 'Other'\n",
    "    \n",
    "    for lname in label_names:\n",
    "        df_group = df_group.replace(lname, grouped_label_name)\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_phylum_data(df_taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(df_taxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120674\n"
     ]
    }
   ],
   "source": [
    "label_names = ['Xanthomonadales', 'Coriobacteriales', 'Vibrionales', 'Alteromonadales', 'Aeromonadales', 'Rhodocyclales', 'Acidimicrobiales', 'Oceanospirillales', 'Cardiobacteriales', 'Chromatiales']\n",
    "df_group = group_labels(df_taxa, label_names)\n",
    "\n",
    "split_data(df_group, level='order', n_samples_per_class=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cdga)",
   "language": "python",
   "name": "cdga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
